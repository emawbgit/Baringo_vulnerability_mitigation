qui cd "${gsdTemp}"
qui spshape2dta "${gsdDataRaw}\household_count_wb_2016/sublocations_baringo.shp", replace //sublocations

**# Process DEM (sublocation-level average elevation values)
qui import delimited "G:\My Drive\earthengine\kenya\baringo work/Baringo_dem_bysublocation.csv", clear
duplicates drop objectid_1,force
rename mean elevation
lab var elevation "Sublocation average elevation"
qui save "${gsdTemp}/dem.dta", replace 

**# Process census 2019 household level data
*1) Retrieve sublocation variable for linking census data and shapefile
use "${gsdDataRaw}\census 2019/Baringo 2019TenPercent_Population and Household Modules.dta", clear 
duplicates drop COUNTY subcounty_code divisionname_code locationname_code sublocation_code EA STRNUMBER HHNUMBER, force
qui export excel COUNTY subcounty_code divisionname_code locationname_code sublocation_code EA STRNUMBER HHNUMBER LISTING_GPS_LATITUDE LISTING_GPS_LONGITUDE using "${gsdTemp}\hh_census2019.xls", firstrow(variables) nolabel replace
qui cd "${gsdTemp}"
qui spshape2dta "${gsdDataRaw}\census 2019/hh_2019_census_sublocationinfo.shp", replace //sublocations
use "${gsdTemp}/hh_2019_census_sublocationinfo.dta", clear 
rename (OBJECTID_1 subcounty_ divisionna locationna sublocatio) (objectid_1 subcounty_code divisionname_code locationname_code sublocation_code)
tempfile hh_2019_census_sublocationinfo
qui save `hh_2019_census_sublocationinfo', replace
use "${gsdDataRaw}\census 2019/Baringo 2019TenPercent_Population and Household Modules.dta", clear 
merge m:1 subcounty_code divisionname_code locationname_code sublocation_code EA STRNUMBER HHNUMBER using `hh_2019_census_sublocationinfo', keepusing(objectid_1) keep(3) nogen
egen hhid=group(subcounty_code divisionname_code locationname_code sublocation_code EA STRNUMBER HHNUMBER)
merge m:1 objectid_1 using "${gsdDataRaw}/popvars.dta", nogen keep(3) keepusing(area_sqkm) //sublocations area
keep if inlist(objectid_1, 4695,	4697,	4698,	4699,	4700,	4701,	4702,	4703,	4704,	4705,	4706,	4707,	4708,	4709,	4710,	4711,	4714,	4715,	4716,	4718,	4719,	4720,	4721,	4722,	4723,	4724,	4728,	4729,	4730,	4750,	4752,	4771,	4805,	4806,	4807,	4808,	4809,	4810,	4811,	4813,	4864,	4867,	4868,	4872,	4873,	4879,	4880,	4881,	4889,	4890,	4891,	4892,	4893,	4899,	4900)

*2) Construct socio-economic variables 

*Population count by sublocation
bys objectid_1: egen tot_population_bysl=count(objectid_1)

*Dependency ratio 
gen below15=(P12>=0 & P12<15)
gen above65=(P12>=65) & !mi(P12)
gen between_15_64=(P12>=15 & P12<65) 
bys hhid: egen totbelow15=total(below15)
bys hhid: egen totbetween_15_64=total(between_15_64)
bys hhid: egen totabove65=total(above65)
bys hhid: gen tot_hh_members=_N
gen hh_depshare=((totbelow15+totabove65)/tot_hh_members)
lab var hh_depshare "Household share of dependent people"

*Disability ratio
forval i=1/6 {
	gen P42_`i'_yn=inlist(P42_`i',2,3,4)
}
egen number_disabilitites=rowtotal(P42_*_yn),m
gen disable=number_disabilitites>0 & !mi(number_disabilitites)
bys hhid: egen tot_disable=total(disable)
gen hh_disableshare=tot_disable/tot_hh_members
lab var hh_disableshare "Household share of disable people"

*Household head is female
gen hhh_female=P10==1 & P11==2
*Household head is employed 
gen hhh_unemployed=mi(P50) & P10==1
*Education level
recode P46A (1 3 7 9 =1) (4 =2) (5 6= 3), gen(education)
*Use of telcom score
egen telcom_score=rowtotal(P55 P57 P58)
replace telcom_score=0 if telcom_score>3
*Asset index 
foreach v of varlist H39_1 H39_2 H39_3 H39_4 H39_5 H39_6 H39_7 H39_8 H39_9 H39_10 H39_11 H39_12 H39_13 H39_14 H39_15 H39_16 H39_17 H39_18 H39_19 {
	replace `v'=0 if `v'==2
}
pca H39_1 H39_2 H39_3 H39_4 H39_5 H39_6 H39_7 H39_8 H39_9 H39_10 H39_11 H39_12 H39_13 H39_14 H39_15 H39_16 H39_17 H39_18 H39_19, components(3)
predict asset_index_pca, score
norm asset_index_pca,method(mmx)
*N. cattle owned 
egen number_cattle=rowtotal(H26_1A H26_2A H26_3A H26_4A H26_5A H26_6A H26_7A H26_8A H26_9A H26_10A H26_11A H26_12 H26_12A H26_15A H30)
*Dwelling characterisctics 
//Roof 
recode H30 (2 3 4 12 =1) (5 6 7 =2) (8 9 10 19 11 12= 3), gen(roof)
fre roof
//Wall
recode H31 (2 3 4 16 =1) (5 6 7 8 9 10 =2) (11 12 13 14 15 17= 3), gen(wall)
fre wall
//Floor
recode H32 (1 2 3 =1) (4 5 6 =2) (7 8 9= 3), gen(floor)
fre floor
//Drinking water source 
recode H33 (1 2 3 4 6 8=1) (5 7 9 13 15=2) (10 11 12 14= 3), gen(drinkwatersource)
fre drinkwatersource
//Toilet type 
recode H34 (8 1 6 3 7=1) (2 5 4 =2) (9= 3), gen(toilettype)
fre toilettype
//Type of cooking fuel
recode H37 (5 6=1) (2 7 =2) (3 4 1= 3), gen(cookingfuel)
fre cookingfuel
//Type of lighting fuel 
recode H38 (10 6 =1) (2 3 4 5 7 8 9 11 13 =2) (1= 3), gen(lightingfuel)
fre lightingfuel
*Flag subsistence farming household
gen subsistence_farming=H20==1
clonevar n_rooms=H28
*Flag poor household
gen hh_poor=inlist(CENSUS_WEALTH_QUINTILE,1,2)

*3) Collapse dataset at household level
keep if P10==1
duplicates drop hhid,force

*Population density by sublocation
gen population_density_bysl=tot_population_bysl/area_sqkm
norm population_density_bysl, method(mmx)

*If missing hh head education, assume primary 
replace education=1 if mi(education)

*5) Collapse indicators at sublocation level
gcollapse mmx_population_density_bysl hh_depshare hhh_unemployed education n_rooms telcom_score number_cattle roof wall floor drinkwatersource toilettype cookingfuel lightingfuel CENSUS_WEALTH_QUINTILE population_density_bysl hhh_female subsistence_farming hh_disableshare hh_poor H39_1 H39_2 H39_3 H39_4 H39_5 H39_6 H39_7 H39_8 H39_9 H39_10 H39_11 H39_12 H39_13 H39_14 H39_15 H39_16 H39_17 H39_18 H39_19, by(objectid_1)
mdesc *

**# Include roads density and include it in the sublocation-level dataset 
preserve 
qui import excel "${gsdDataRaw}\roads_density.xlsx", sheet("Sheet1") firstrow clear
renvars *, lower
lab var roadkm_km2 "Road density (km/km2)"
tempfile roads_density
qui save `roads_density', replace
restore 
merge 1:1 objectid_1 using `roads_density', keepusing(roadkm_km2 shape_area)  nogen keep(1 3)
mdesc 
foreach v of varlist roadkm_km2 hh_depshare hh_disableshare hhh_female hhh_unemployed hh_poor subsistence_farming {
	norm `v', method(mmx)
}

//Exposure
global exposure mmx_population_density_bysl mmx_roadkm_km2

//Susceptibility
global susceptibility mmx_hh_depshare mmx_hh_disableshare mmx_hhh_female mmx_hhh_unemployed mmx_hh_poor mmx_subsistence_farming

//Adaptability
*Dwelling quality
pca n_rooms roof wall floor drinkwatersource toilettype cookingfuel lightingfuel, components(2)
predict dwelling_quality, score
norm dwelling_quality,method(mmx)

*Asset ownership 
pca H39_1 H39_2 H39_3 H39_4 H39_5 H39_6 H39_7 H39_8 H39_9 H39_10 H39_11 H39_12 H39_13 H39_14 H39_15 H39_16 H39_17 H39_18 H39_19, components(3)
predict asset_ownership, score
norm asset_ownership,method(mmx)

*Education 
norm education,method(mmx)

global adaptability mmx_dwelling_quality mmx_asset_ownership mmx_education

summ $exposure $susceptibility $adaptability
mdesc $exposure $susceptibility $adaptability
foreach v of varlist $exposure $susceptibility $adaptability {
	qui replace `v'=.00001 if `v'<.00001
}
qui savesome objectid_1 $exposure $susceptibility $adaptability using  "${gsdTemp}\svi_criteria.dta", replace


*Calculate SVI with MCA: i.e. we impose the maximization of a vulnerability function based on criteria for exposure, susceptibility and adaptability
qui export excel objectid_1 $exposure $susceptibility $adaptability using "${gsdDo}/topsis_criteria_svi.xlsx", replace firstrow(variables)
mata: setheader("${gsdDo}/topsis_criteria_svi.xlsx", "Sheet1")

**# Import and store weights and impact parameters (as per discussion in excel reference table)
qui import excel "${gsdDo}\topsis_setup_svi.xlsx", sheet("Sheet1") firstrow clear
rename (Impact Weight) (impact weight)
qui export excel impact if !mi(impact) using "${gsdDo}\topsis_impact_svi.xlsx", firstrow(variables) replace //impacts (gains or costs)
mata: setheader("${gsdDo}\topsis_impact_svi.xlsx", "Sheet1")
qui export excel weight if !mi(weight) using "${gsdDo}\topsis_weight_svi.xlsx", firstrow(variables) replace //weights
mata: setheader("${gsdDo}\topsis_weight_svi.xlsx", "Sheet1")

**# Run geotopsis
rsource using "${gsdDo}\topsis_svi.R", roptions("--vanilla") rpath("C:/PROGRA~1/R/R-42~1.2/bin/x64/R")

**# Import the results of the geotopsis and normalize them 
qui import excel "${gsdOutput}/topsisoutcome_svi.xlsx", sheet("Sheet1") firstrow clear
norm score, method(mmx)
rename mmx_score svi
merge 1:1 objectid_1 using "${gsdTemp}\svi_criteria.dta", keep(3) nogen
erase "${gsdTemp}\svi_criteria.dta"
qui save "${gsdTemp}/svi.dta", replace 

**# Get area covered by water between 2003 and 2023. Compute the variation btw years and normalize it by sublocation total area. Data on water cover taken from Landsat 7 and 8 via Google Earth Engine
import excel "${gsdDataRaw}\water_extent_bysl_20032023.xlsx", sheet("Foglio2") firstrow clear
dropmiss *, force
drop if mi(sublocation)
split sublocation,p("_")
rename sublocation2 objectid_1
destring objectid_1, replace 
merge 1:1 objectid_1 using `roads_density', keepusing(shape_area)  nogen keep(3)
gen water_prop_2003=extent_2003/(shape_area/1000000)
gen water_prop_2023=extent_2023/(shape_area/1000000)
gen new_perm_water_area_share=(water_prop_2023/water_prop_2003)-1
replace new_perm_water_area_share=0 if mi(new_perm_water_area_share)
lab var new_perm_water_area_share "Percent variation in new water within each sublocation. Normalized by sublocation area"
keeporder sublocation objectid_1 extent_2003 extent_2023 shape_area water_prop_2003 water_prop_2023 new_perm_water_area_share
qui save "${gsdTemp}/new_permanentwater.dta", replace 

**# Process NDVI time series 
import delimited "G:\My Drive\earthengine\kenya\baringo work\Ndvi_sublocations_baringo_ts.csv", clear
rename imageid imageid_s
gen imageid = subinstr(imageid_s,"_","",.)
destring imageid, replace force
order objectid_1 imageid_s imageid mean
rename mean ndvi
tempfile ndvi_ts
qui save `ndvi_ts', replace 

**# Process rainfall variables 
** Import CHIPRS long term averages and sd data (sensor-level daily values retrieved via Google Earth Engine API: https://code.earthengine.google.com/cc54cb03160cc5de5f14a50f33906caf)
qui import delimited "G:\My Drive\earthengine\kenya\baringo work\Baringo_subloc_chirps_1983012023011.csv", clear 
merge 1:1 objectid_1 imageid using `ndvi_ts', keepusing(ndvi) keep(1 3) nogen
//keep if imageid>20030101 //restrict data from 2003 for time span comparability
preserve 
//keep if inlist(objectid_1,4700,	4701,	4702	,4719	,4720	4752	,4771	,4805,	4806,	4808	,4809,	4810)
keep if inlist(objectid_1, 4695,	4697,	4698,	4699,	4700,	4701,	4702,	4703,	4704,	4705,	4706,	4707,	4708,	4709,	4710,	4711,	4714,	4715,	4716,	4718,	4719,	4720,	4721,	4722,	4723,	4724,	4728,	4729,	4730,	4750,	4752,	4771,	4805,	4806,	4807,	4808,	4809,	4810,	4811,	4813,	4864,	4867,	4868,	4872,	4873,	4879,	4880,	4881,	4889,	4890,	4891,	4892,	4893,	4899,	4900)
collapse (sum) mean (mean) ndvi, by(imageid)
qui tostring imageid,gen(imageids)
qui gen y=substr(imageids,1,4)
qui gen m=substr(imageids,5,2)
//keep if inlist(m,"03", "04", "05", "10", "11", "12") //restrict to rainy season
collapse (sum) mean (mean) ndvi, by(y) 
destring y, replace
xtset y
multiline mean ndvi y, recast(connected) xlabel(2003(5)2023) xtitle(`"Year"') 
rename mean rain
regress rain y 
predict rain_h, xb
lab var rain "Total annual rainfall"
lab var rain_h "Trend line"
qui ktau y rain 
twoway (line rain y) (line rain_h y, lcolor(lime)), ytitle(`"Millimiters"', size(small)) ylabel(#4) xtitle(`"Year"', size(small)) xlabel(1983(5)2023) title(`"Cumulative average rainfall"') caption(`"Kendall Trend test p-value: `r(p)'"') saving("${gsdTemp}/rain_ts", replace)
qui graph export "${gsdTemp}\cum_rain_ts_baringo.png", as(png) name("Graph") replace
*Show time trend for NDVI
regress ndvi y 
predict ndvi_h, xb
lab var ndvi "NDVI"
lab var ndvi_h "Trend line"
qui ktau y ndvi 
twoway (line ndvi y ) (line ndvi_h y, lcolor(lime)) if y>2002, ytitle(`"NDVI"', size(small)) ylabel(#4) xtitle(`"Year"', size(small)) xlabel(2003(5)2023) title(`"Average NDVI"') caption(`"Kendall Trend test p-value: `r(p)'"') saving("${gsdTemp}/ndvi_ts", replace)
qui graph export "${gsdTemp}\avg_ndvi_ts_baringo.png", as(png) name("Graph") replace
*Combine graph for rain and ndvi
qui gr combine rain_ts.gph ndvi_ts.gph, style(sj)
qui graph export "${gsdTemp}\lfit_combined.png", as(png) name("Graph") replace
restore 
*Prepare smaller datasets for reshape and calculation of weather metrics
rename mean pic_
drop ndvi
qui tostring imageid,gen(imageids)
qui gen y=substr(imageids,1,4)
qui destring y, replace force
local sy 1981
forval i=1981/2022 {	
	local ey=`sy'+5
	qui savesome if inrange(y,`sy',`ey') using "${gsdTemp}/chirps_y`sy'_y`ey'.dta", replace 
	local sy=`ey'
}
*Reshape the splitted dataset
qui filelist, dir("${gsdTemp}/") pat("chirps_y*.dta") norec //files to reshape
qui levelsof filename if fsize>4639,local(filestoreshape) //store their names in local
foreach f of local filestoreshape { //for each file to be erased
	use "${gsdTemp}/`f'", clear
	drop y imageids
	qui greshape wide pic_, i(objectid_1) j(imageid)
	qui save "${gsdTemp}/wide_`f'", replace
	erase "${gsdTemp}/`f'" //erase it
}
*Merge into a unique arable_barcode level wide time series
use "${gsdTemp}/wide_chirps_y1981_y1986.dta", clear 
preserve 
qui filelist, dir("${gsdTemp}/") pat("wide_*") norec //files to merge
qui levelsof filename if filename !="wide_chirps_y1981_y1986.dta",local(filestomerge) //store their names in local
restore
foreach f of local filestomerge { //for each file to be merged
	qui merge 1:1 objectid_1 using "${gsdTemp}/`f'", nogen keep(3)  //assert(3)
	qui erase "${gsdTemp}/`f'"
}
qui save "${gsdTemp}/wide_chirps_y1983_y2023.dta", replace 
use  "${gsdTemp}/wide_chirps_y1983_y2023.dta", clear
drop pic_20230101- pic_20230801
**# Compute season specific weather metrics
weather pic_, rain_data ini_month(3) fin_month(5) day_month(15) keep(objectid_1)
global historic_values total_season_1983 total_season_1984 total_season_1985 total_season_1986 total_season_1987 total_season_1988 total_season_1989 total_season_1990 total_season_1991 total_season_1992 total_season_1993 total_season_1994 total_season_1995 total_season_1996 total_season_1997 total_season_1998 total_season_1999 total_season_2000 total_season_2001 total_season_2002 total_season_2003 total_season_2004 total_season_2005 total_season_2006 total_season_2007 total_season_2008 total_season_2009 total_season_2010 total_season_2011 total_season_2012 total_season_2013 total_season_2014
egen lt_mtr_avg=rowmean($historic_values)
egen lt_mtr_sd=rowsd($historic_values)
forval y=2015/2022 {
	gen outlier_rs_`y'=total_season_`y'>(lt_mtr_avg+(1.95*lt_mtr_sd))
}
egen n_sign_high_totprec_rs=rowtotal(outlier_rs_*)
qui save "${gsdTemp}/rain_shocks.dta", replace 

**# Build dataset for MCDA
use "${gsdTemp}/sublocations_baringo.dta",clear 
rename OBJECTID_1 objectid_1
keep if inlist(objectid_1, 4695,	4697,	4698,	4699,	4700,	4701,	4702,	4703,	4704,	4705,	4706,	4707,	4708,	4709,	4710,	4711,	4714,	4715,	4716,	4718,	4719,	4720,	4721,	4722,	4723,	4724,	4728,	4729,	4730,	4750,	4752,	4771,	4805,	4806,	4807,	4808,	4809,	4810,	4811,	4813,	4864,	4867,	4868,	4872,	4873,	4879,	4880,	4881,	4889,	4890,	4891,	4892,	4893,	4899,	4900)
merge 1:1 objectid_1 using "${gsdTemp}/dem.dta", nogen keep(3) keepusing(elevation) //merge average elevation
merge 1:1 objectid_1 using "${gsdTemp}/svi.dta", nogen keep(1 3)  keepusing(svi $exposure $susceptibility $adaptability) //socio-economic indicators from the 2019 census
merge 1:1 objectid_1 using "${gsdTemp}/rain_shocks.dta", nogen keep(1 3) keepusing(n_sign_high_totprec_rs) //number of rain shock events
merge 1:1 objectid_1 using "${gsdTemp}/new_permanentwater.dta", nogen keep(1 3) keepusing(new_perm_water_area_share) //proportion of sublocation surface that is newly permanent waters
keeporder _ID _CX _CY objectid_1 elevation new_perm_water_area_share svi $exposure $susceptibility $adaptability
norm elevation, method(mmx)
************************************************************************************
**# Setup topsis on Baringo sublocations
************************************************************************************
rename new_perm_water_area_share newpermwat_share
norm newpermwat_share, method(mmx)
drop newpermwat_share 
lab var mmx_newpermwat_share "Proportion of sublocation area that is covered with newly permanent water (0-1 normalized value)"

*Spatially visualize variables
qui grmap, activate
//Average elevation
qui grmap mmx_elevation, title("Baringo county", size(*0.8)) subtitle("Average normalized elevation",size(*0.6))  fcolor(BuYlRd) legstyle(3) cln(4) legtitle(Variable) legenda(on) legend(ring(1) position(2)) 
qui graph export "${gsdOutput}/avg_elevation.jpg", as(jpg) quality(100) name("Graph") replace
//Average share of new permanent water
grmap mmx_newpermwat_share, title("Baringo county", size(*0.8)) subtitle("Average normalized share of new permanent water",size(*0.6))  fcolor(BuYlRd) legstyle(3) cln(4) legtitle(Variable) legenda(on) legend(ring(1) position(2)) 
qui graph export "${gsdOutput}\avg_newpermwater.jpg", as(jpg) quality(100) name("Graph") replace
//Average social vulnerability score
grmap svi, title("Baringo county", size(*0.8)) subtitle("Average normalized SVI",size(*0.6))  fcolor(BuYlRd) legstyle(3) cln(4) legtitle(Variable) legenda(on) legend(ring(1) position(2)) 
qui graph export "${gsdOutput}\avg_svi.jpg", as(jpg) name("Graph") quality(100) replace
qui save "${gsdOutput}/baringo_dataset_mcda.dta", replace 

use "${gsdOutput}/baringo_dataset_mcda.dta", clear 
**# Define the criteria to be fed into the analysis (grouped by thematic area)
global natural mmx_newpermwat_share mmx_elevation //natural factors
global socioeconomic svi //socioeconomic factors
mdesc objectid_1 $natural $socioeconomic
foreach v of varlist $natural $socioeconomic {
	replace `v'=0.0000001 if mi(`v') | `v'<0.0000001
}
summ  $natural $socioeconomic
qui export excel objectid_1 $natural $socioeconomic using "${gsdDo}/topsis_criteria_baringo.xlsx", replace firstrow(variables)
mata: setheader("${gsdDo}/topsis_criteria_baringo.xlsx", "Sheet1")

egen max_mmx_newpermwat_share=max(mmx_newpermwat_share)
egen max_svi=max(svi)
egen min_mmx_elevation=max(mmx_elevation)

gen water_dist_weighted=((mmx_newpermwat_share-max_mmx_newpermwat_share)^2)*.45
gen elevation_dist_weighted=((mmx_elevation-min_mmx_elevation)^2)*.05
gen svi_dist_weighted=((svi-max_svi)^2)*.5

gen weighted_dist=elevation_dist_weighted/(water_dist_weighted+elevation_dist_weighted+svi_dist_weighted)
br mmx_newpermwat_share mmx_elevation svi max_mmx_newpermwat_share max_svi min_mmx_elevation water_dist_weighted elevation_dist_weighted svi_dist_weighted weighted_dist
xtile geotopsis_categories = weighted_dist, nq(5) //create quartiles on normalized values


qui grmap, activate
//Average elevation
qui grmap geotopsis_categories, title("Baringo county", size(*0.8)) subtitle("Average normalized elevation",size(*0.6))  fcolor(BuYlRd) legstyle(3) cln(5) legtitle(Variable) legenda(on) legend(ring(1) position(2)) 

**# Import and store weights and impact parameters (as per discussion in excel reference table)
qui import excel "${gsdDo}\topsis_setup_baringo.xlsx", sheet("Sheet1") firstrow clear
rename (Impact Weight) (impact weight)
qui export excel impact if !mi(impact) using "${gsdDo}\topsis_impact_baringo.xlsx", firstrow(variables) replace //impacts (gains or costs)
mata: setheader("${gsdDo}\topsis_impact_baringo.xlsx", "Sheet1")
qui export excel weight if !mi(weight) using "${gsdDo}\topsis_weight_baringo.xlsx", firstrow(variables) replace //weights
mata: setheader("${gsdDo}\topsis_weight_baringo.xlsx", "Sheet1")

**# Run geotopsis
qui rsource using "${gsdDo}\topsis_baringo.R", roptions("--vanilla") rpath("C:/PROGRA~1/R/R-42~1.2/bin/x64/R")

**# Import the results of the geotopsis 
qui import excel "${gsdOutput}/topsisoutcome_baringo.xlsx", sheet("Sheet1") firstrow clear
rename score geotopsis_score
merge 1:1 objectid_1 using "${gsdOutput}/baringo_dataset_mcda.dta",  nogen keep(3)
keeporder _ID _CX _CY objectid_1  geotopsis_score
norm geotopsis_score, method(mmx) //normalize topsis score (0 to 1)
xtile geotopsis_categories = mmx_geotopsis_score, nq(4) //create quartiles on normalized values

**# Visualize results on map
qui spset 
qui grmap, activate
grmap mmx_geotopsis_score,  title("Geotopsis results", size(*0.8)) subtitle("Baringo sublocation",size(*0.6)) note("", size(*0.7)) fcolor(BuYlRd) legstyle(3) cln(4) legtitle(Normalized geotopsis quartile) legenda(on) legend(ring(1) position(2))
qui graph export "${gsdOutput}\topsis_baringo.jpg", as(jpg) name("Graph") quality(100) replace

**# Export attribute table, with codebook and the addition of the topsis score
lab var geotopsis_score "Geotopsis score"
lab var mmx_geotopsis_score "Normalized (0-1) Geotopsis score"
lab var geotopsis_categories "Normalized Geotopsis score quartiles"
qui iecodebook export using "${gsdOutput}/topsis_baringo.xlsx", replace 
qui export excel using "${gsdOutput}/topsis_baringo.xlsx", sheet("attribute_table") sheetreplace firstrow(variables)
import excel "${gsdOutput}/topsis_baringo.xlsx", sheet("survey") firstrow clear
qui export excel name label	type using "${gsdOutput}/topsis_baringo.xlsx", sheet("codebook") sheetreplace firstrow(variables)

preserve 
qui import excel "${gsdDo}\topsis_criteria_baringo.xlsx", sheet("Sheet1") firstrow clear
dropmiss *,force
tempfile topsis_baringo_criteriavals 
qui save `topsis_baringo_criteriavals', replace 
restore 
qui import excel "${gsdOutput}/topsis_baringo.xlsx", sheet("attribute_table") firstrow clear
merge 1:1 objectid_1 using `topsis_baringo_criteriavals', keepusing($natural $socioeconomic) nogen assert(3) keep(3)
sort geotopsis_categories
qui export excel using "${gsdOutput}/topsis_baringo.xlsx", sheet("attribute_table") sheetreplace firstrow(variables)
mata: setheader("${gsdOutput}/topsis_baringo.xlsx", "codebook")
mata: setheader("${gsdOutput}/topsis_baringo.xlsx", "attribute_table")
erase "${gsdOutput}/topsisoutcome_baringo.xlsx"

