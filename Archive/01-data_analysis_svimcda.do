qui cd "${gsdTemp}"
qui spshape2dta "${gsdDataRaw}\household_count_wb_2016/sublocations_baringo.shp", replace //sublocations

**# Process DEM (sublocation-level average elevation values)
qui import delimited "G:\My Drive\earthengine\kenya\baringo work/Baringo_dem_bysublocation.csv", clear
duplicates drop objectid_1,force
rename mean elevation
lab var elevation "Sublocation average elevation"
qui save "${gsdTemp}/dem.dta", replace 

**# Process census 2019 household level data
*1) Retrieve sublocation variable for linking census data and shapefile
use "${gsdDataRaw}\census 2019/Baringo 2019TenPercent_Population and Household Modules.dta", clear 
duplicates drop COUNTY subcounty_code divisionname_code locationname_code sublocation_code EA STRNUMBER HHNUMBER, force
qui export excel COUNTY subcounty_code divisionname_code locationname_code sublocation_code EA STRNUMBER HHNUMBER LISTING_GPS_LATITUDE LISTING_GPS_LONGITUDE using "${gsdTemp}\hh_census2019.xls", firstrow(variables) nolabel replace
qui cd "${gsdTemp}"
qui spshape2dta "${gsdDataRaw}\census 2019/hh_2019_census_sublocationinfo.shp", replace //sublocations
use "${gsdTemp}/hh_2019_census_sublocationinfo.dta", clear 
rename (OBJECTID_1 subcounty_ divisionna locationna sublocatio) (objectid_1 subcounty_code divisionname_code locationname_code sublocation_code)
tempfile hh_2019_census_sublocationinfo
qui save `hh_2019_census_sublocationinfo', replace
use "${gsdDataRaw}\census 2019/Baringo 2019TenPercent_Population and Household Modules.dta", clear 
merge m:1 subcounty_code divisionname_code locationname_code sublocation_code EA STRNUMBER HHNUMBER using `hh_2019_census_sublocationinfo', keepusing(objectid_1) keep(3) nogen
egen hhid=group(subcounty_code divisionname_code locationname_code sublocation_code EA STRNUMBER HHNUMBER)
merge m:1 objectid_1 using "${gsdTemp}/popvars.dta", nogen keep(3) keepusing(area_sqkm) //population density variables 
keep if inlist(objectid_1, 4695,	4697,	4698,	4699,	4700,	4701,	4702,	4703,	4704,	4705,	4706,	4707,	4708,	4709,	4710,	4711,	4714,	4715,	4716,	4718,	4719,	4720,	4721,	4722,	4723,	4724,	4728,	4729,	4730,	4750,	4752,	4771,	4805,	4806,	4807,	4808,	4809,	4810,	4811,	4813,	4864,	4867,	4868,	4872,	4873,	4879,	4880,	4881,	4889,	4890,	4891,	4892,	4893,	4899,	4900)

*2) Construct socio-economic variables 

*Population count by sublocation
bys objectid_1: egen tot_population_bysl=count(objectid_1)

*Dependency ratio 
gen below15=(P12>=0 & P12<15)
gen above65=(P12>=65) & !mi(P12)
gen between_15_64=(P12>=15 & P12<65) 
bys hhid: egen totbelow15=total(below15)
bys hhid: egen totbetween_15_64=total(between_15_64)
bys hhid: egen totabove65=total(above65)
bys hhid: gen tot_hh_members=_N
gen hh_depshare=((totbelow15+totabove65)/tot_hh_members)
lab var hh_depshare "Household share of dependent people"

*Disability ratio
forval i=1/6 {
	gen P42_`i'_yn=inlist(P42_`i',2,3,4)
}
egen number_disabilitites=rowtotal(P42_*_yn),m
gen disable=number_disabilitites>0 & !mi(number_disabilitites)
bys hhid: egen tot_disable=total(disable)
gen hh_disableshare=tot_disable/tot_hh_members
lab var hh_disableshare "Household share of disable people"

*Household head is female
gen hhh_female=P10==1 & P11==2
*Household head is employed 
gen hhh_unemployed=mi(P50) & P10==1
*Education level
recode P46A (1 3 7 9 =1) (4 =2) (5 6= 3), gen(education)
*Use of telcom score
egen telcom_score=rowtotal(P55 P57 P58)
replace telcom_score=0 if telcom_score>3
*Asset index 
foreach v of varlist H39_1 H39_2 H39_3 H39_4 H39_5 H39_6 H39_7 H39_8 H39_9 H39_10 H39_11 H39_12 H39_13 H39_14 H39_15 H39_16 H39_17 H39_18 H39_19 {
	replace `v'=0 if `v'==2
}
pca H39_1 H39_2 H39_3 H39_4 H39_5 H39_6 H39_7 H39_8 H39_9 H39_10 H39_11 H39_12 H39_13 H39_14 H39_15 H39_16 H39_17 H39_18 H39_19, components(3)
predict asset_index_pca, score
norm asset_index_pca,method(mmx)
*N. cattle owned 
egen number_cattle=rowtotal(H26_1A H26_2A H26_3A H26_4A H26_5A H26_6A H26_7A H26_8A H26_9A H26_10A H26_11A H26_12 H26_12A H26_15A H30)
*Dwelling characterisctics 
//Roof 
recode H30 (2 3 4 12 =1) (5 6 7 =2) (8 9 10 19 11 12= 3), gen(roof)
fre roof
//Wall
recode H31 (2 3 4 16 =1) (5 6 7 8 9 10 =2) (11 12 13 14 15 17= 3), gen(wall)
fre wall
//Floor
recode H32 (1 2 3 =1) (4 5 6 =2) (7 8 9= 3), gen(floor)
fre floor
//Drinking water source 
recode H33 (1 2 3 4 6 8=1) (5 7 9 13 15=2) (10 11 12 14= 3), gen(drinkwatersource)
fre drinkwatersource
//Toilet type 
recode H34 (8 1 6 3 7=1) (2 5 4 =2) (9= 3), gen(toilettype)
fre toilettype
//Type of cooking fuel
recode H37 (5 6=1) (2 7 =2) (3 4 1= 3), gen(cookingfuel)
fre cookingfuel
//Type of lighting fuel 
recode H38 (10 6 =1) (2 3 4 5 7 8 9 11 13 =2) (1= 3), gen(lightingfuel)
fre lightingfuel
*Flag subsistence farming household
gen subsistence_farming=H20==1
clonevar n_rooms=H28
*Flag poor household
gen hh_poor=inlist(CENSUS_WEALTH_QUINTILE,1,2)

*3) Collapse dataset at household level
keep if P10==1
duplicates drop hhid,force

*Population density by sublocation
gen population_density_bysl=tot_population_bysl/area_sqkm
norm population_density_bysl, method(mmx)

*If missing hh head education, assume primary 
replace education=1 if mi(education)

*5) Collapse indicators at sublocation level
gcollapse mmx_population_density_bysl hh_depshare hhh_unemployed education n_rooms telcom_score number_cattle roof wall floor drinkwatersource toilettype cookingfuel lightingfuel CENSUS_WEALTH_QUINTILE population_density_bysl hhh_female subsistence_farming hh_disableshare hh_poor H39_1 H39_2 H39_3 H39_4 H39_5 H39_6 H39_7 H39_8 H39_9 H39_10 H39_11 H39_12 H39_13 H39_14 H39_15 H39_16 H39_17 H39_18 H39_19, by(objectid_1)
mdesc *

**# Include roads density and include it in the sublocation-level dataset 
preserve 
qui import excel "${gsdDataRaw}\roads_density.xlsx", sheet("Sheet1") firstrow clear
renvars *, lower
lab var roadkm_km2 "Road density (km/km2)"
tempfile roads_density
qui save `roads_density', replace
restore 
merge 1:1 objectid_1 using `roads_density', keepusing(roadkm_km2 shape_area)  nogen keep(1 3)
mdesc 
foreach v of varlist roadkm_km2 hh_depshare hh_disableshare hhh_female hhh_unemployed hh_poor subsistence_farming {
	norm `v', method(mmx)
}

//Exposure
global exposure mmx_population_density_bysl mmx_roadkm_km2

//Susceptibility
global susceptibility mmx_hh_depshare mmx_hh_disableshare mmx_hhh_female mmx_hhh_unemployed mmx_hh_poor mmx_subsistence_farming

//Adaptability
*Dwelling quality
pca n_rooms roof wall floor drinkwatersource toilettype cookingfuel lightingfuel, components(2)
predict dwelling_quality, score
norm dwelling_quality,method(mmx)

*Asset ownership 
pca H39_1 H39_2 H39_3 H39_4 H39_5 H39_6 H39_7 H39_8 H39_9 H39_10 H39_11 H39_12 H39_13 H39_14 H39_15 H39_16 H39_17 H39_18 H39_19, components(3)
predict asset_ownership, score
norm asset_ownership,method(mmx)

*Education 
norm education,method(mmx)

global adaptability mmx_dwelling_quality mmx_asset_ownership mmx_education

summ $exposure $susceptibility $adaptability
mdesc $exposure $susceptibility $adaptability
foreach v of varlist $exposure $susceptibility $adaptability {
	qui replace `v'=.00001 if `v'<.00001
}
qui savesome objectid_1 $exposure $susceptibility $adaptability using  "${gsdTemp}\svi_criteria.dta", replace


*Calculate SVI with MCA: i.e. we impose the maximization of a vulnerability function based on criteria for exposure, susceptibility and adaptability
qui export excel objectid_1 $exposure $susceptibility $adaptability using "${gsdDo}/topsis_criteria_svi.xlsx", replace firstrow(variables)
mata: setheader("${gsdDo}/topsis_criteria_svi.xlsx", "Sheet1")

**# Import and store weights and impact parameters (as per discussion in excel reference table)
qui import excel "${gsdDo}\topsis_setup_svi.xlsx", sheet("Sheet1") firstrow clear
rename (Impact Weight) (impact weight)
qui export excel impact if !mi(impact) using "${gsdDo}\topsis_impact_svi.xlsx", firstrow(variables) replace //impacts (gains or costs)
mata: setheader("${gsdDo}\topsis_impact_svi.xlsx", "Sheet1")
qui export excel weight if !mi(weight) using "${gsdDo}\topsis_weight_svi.xlsx", firstrow(variables) replace //weights
mata: setheader("${gsdDo}\topsis_weight_svi.xlsx", "Sheet1")

**# Run geotopsis
qui rsource using "${gsdDo}\topsis_svi.R", roptions("--vanilla") rpath("C:/PROGRA~1/R/R-42~1.2/bin/x64/R")

**# Import the results of the geotopsis and normalize them 
qui import excel "${gsdOutput}/topsisoutcome_svi.xlsx", sheet("Sheet1") firstrow clear
norm score, method(mmx)
rename mmx_score svi
merge 1:1 objectid_1 using "${gsdTemp}\svi_criteria.dta", keep(3) assert(3) nogen
erase "${gsdTemp}\svi_criteria.dta"
qui save "${gsdTemp}/svi.dta", replace 

**# Process rainfall variables 
** Import CHIPRS long term averages and sd data (sensor-level daily values retrieved via Google Earth Engine API: https://code.earthengine.google.com/cc54cb03160cc5de5f14a50f33906caf)
qui import delimited "G:\My Drive\earthengine\kenya\baringo work\Baringo_subloc_chirps_1983012023011.csv", clear 
preserve 
keep if inlist(objectid_1, 4695,	4697,	4698,	4699,	4700,	4701,	4702,	4703,	4704,	4705,	4706,	4707,	4708,	4709,	4710,	4711,	4714,	4715,	4716,	4718,	4719,	4720,	4721,	4722,	4723,	4724,	4728,	4729,	4730,	4750,	4752,	4771,	4805,	4806,	4807,	4808,	4809,	4810,	4811,	4813,	4864,	4867,	4868,	4872,	4873,	4879,	4880,	4881,	4889,	4890,	4891,	4892,	4893,	4899,	4900)
collapse (sum) mean, by(imageid)
qui tostring imageid,gen(imageids)
qui gen y=substr(imageids,1,4)
qui gen m=substr(imageids,5,2)
keep if inlist(m,"03", "04", "05", "10", "11", "12")
collapse (sum) mean, by(y) 
destring y, replace
xtset y
regress mean y 
predict mean_h, xb
multiline mean mean_h y, recast(connected)
twoway (line mean y) (line mean_h y, lcolor(lime)), ytitle(`"Millimiters"') xtitle(`"Year"') title(`"Cumulative average rainfall"') subtitle(`"Sublocations within a 20km radius from Baringo and Bogoria Lakes"') caption(`"Rainy seasons months only"')
restore 
rename mean pic_
qui tostring imageid,gen(imageids)
qui gen y=substr(imageids,1,4)
qui destring y, replace force
local sy 1981
forval i=1981/2022 {	
	local ey=`sy'+5
	qui savesome if inrange(y,`sy',`ey') using "${gsdTemp}/chirps_y`sy'_y`ey'.dta", replace 
	local sy=`ey'
}
*Reshape the splitted dataset
qui filelist, dir("${gsdTemp}/") pat("chirps_y*.dta") norec //files to reshape
qui levelsof filename if fsize>4639,local(filestoreshape) //store their names in local
foreach f of local filestoreshape { //for each file to be erased
	use "${gsdTemp}/`f'", clear
	drop y imageids
	qui greshape wide pic_, i(objectid_1) j(imageid)
	qui save "${gsdTemp}/wide_`f'", replace
	erase "${gsdTemp}/`f'" //erase it
}
*Merge into a unique arable_barcode level wide time series
use "${gsdTemp}/wide_chirps_y1981_y1986.dta", clear 
preserve 
qui filelist, dir("${gsdTemp}/") pat("wide_*") norec //files to merge
qui levelsof filename if filename !="wide_chirps_y1981_y1986.dta",local(filestomerge) //store their names in local
restore
foreach f of local filestomerge { //for each file to be merged
	qui merge 1:1 objectid_1 using "${gsdTemp}/`f'", nogen keep(3) assert(3)
	qui erase "${gsdTemp}/`f'"
}
qui save "${gsdTemp}/wide_chirps_y1983_y2023.dta", replace 
use  "${gsdTemp}/wide_chirps_y1983_y2023.dta", clear
drop pic_20230101- pic_20230801
**# Compute season specific weather metrics
weather pic_, rain_data ini_month(3) fin_month(5) day_month(15) keep(objectid_1)
global historic_values total_season_1983 total_season_1984 total_season_1985 total_season_1986 total_season_1987 total_season_1988 total_season_1989 total_season_1990 total_season_1991 total_season_1992 total_season_1993 total_season_1994 total_season_1995 total_season_1996 total_season_1997 total_season_1998 total_season_1999 total_season_2000 total_season_2001 total_season_2002 total_season_2003 total_season_2004 total_season_2005 total_season_2006 total_season_2007 total_season_2008 total_season_2009 total_season_2010 total_season_2011 total_season_2012 total_season_2013 total_season_2014
egen lt_mtr_avg=rowmean($historic_values)
egen lt_mtr_sd=rowsd($historic_values)
forval y=2015/2022 {
	gen outlier_rs_`y'=total_season_`y'>(lt_mtr_avg+(1.95*lt_mtr_sd))
}
egen n_sign_high_totprec_rs=rowtotal(outlier_rs_*)
qui save "${gsdTemp}/rain_shocks.dta", replace 

**# Get number of permanent water pixels for each sublocation. (Cfr JRC dataset - analyzed in Google Earth Engine: https://developers.google.com/earth-engine/datasets/catalog/JRC_GSW1_4_GlobalSurfaceWater . Link: https://code.earthengine.google.com/70407ad9793ed6c1684011b8d7833c02)
qui import delimited "G:\My Drive\earthengine\kenya\baringo work\Count_newpermwater_pxls_jrc.csv", clear
gen new_perm_water_area=(count_newpermwater_pxls*900)/1000000
br count_newpermwater_pxls new_perm_water_area shape_area
gen new_perm_water_area_share=new_perm_water_area/shape_area
qui save "${gsdTemp}/new_permanentwater.dta", replace 

**# Process land cover change variables
//2015-16
qui import delimited "G:\My Drive\earthengine\kenya\baringo work\class_area_by_sublocations_baringo_201516.csv", clear 
renvars water- snow_and_ice,postf(_2015)
tempfile landcover_2015
qui save `landcover_2015', replace 
//2021-22
qui import delimited "G:\My Drive\earthengine\kenya\baringo work\class_area_by_sublocations_baringo_202122.csv", clear 
renvars water- snow_and_ice,postf(_2021)
merge 1:1 objectid_1 using `landcover_2015', keep(3) assert(3) nogen
local classes water trees grass flooded_vegetation crops shrub_and_scrub built bare snow_and_ice
foreach c of local classes {
	qui replace `c'_2015=0 if mi(`c'_2015)
	qui replace `c'_2021=0 if mi(`c'_2021)
	qui gen perc_var_`c'=((`c'_2021/`c'_2015)-1)*100
	qui lab var perc_var_`c' "Percent difference in land cover of class `c' between 2015 and 2021"
}
qui save "${gsdTemp}/landcover_change.dta", replace

**# Build dataset for MCDA
use "${gsdTemp}/sublocations_baringo.dta",clear 
rename OBJECTID_1 objectid_1
keep if inlist(objectid_1, 4695,	4697,	4698,	4699,	4700,	4701,	4702,	4703,	4704,	4705,	4706,	4707,	4708,	4709,	4710,	4711,	4714,	4715,	4716,	4718,	4719,	4720,	4721,	4722,	4723,	4724,	4728,	4729,	4730,	4750,	4752,	4771,	4805,	4806,	4807,	4808,	4809,	4810,	4811,	4813,	4864,	4867,	4868,	4872,	4873,	4879,	4880,	4881,	4889,	4890,	4891,	4892,	4893,	4899,	4900)
merge 1:1 objectid_1 using "${gsdTemp}/dem.dta", nogen keep(3) keepusing(elevation) //merge average elevation
merge 1:1 objectid_1 using "${gsdTemp}/landcover_change.dta", nogen keep(3) keepusing(perc_var_*) //change in land cover 2015-2021 as per dynamic world cover dataset
merge 1:1 objectid_1 using "${gsdTemp}/svi.dta", nogen keep(1 3)  keepusing(svi $exposure $susceptibility $adaptability) //socio-economic indicators from the 2019 census
merge 1:1 objectid_1 using "${gsdTemp}/rain_shocks.dta", nogen keep(1 3) keepusing(n_sign_high_totprec_rs) //number of rain shock events
merge 1:1 objectid_1 using "${gsdTemp}/new_permanentwater.dta", nogen keep(1 3) keepusing(new_perm_water_area_share) //proportion of sublocation surface that is newly permanent waters
keeporder _ID _CX _CY objectid_1 elevation perc_var_water new_perm_water_area_share svi $exposure $susceptibility $adaptability
norm elevation, method(mmx)
************************************************************************************
**# Setup topsis on Baringo sublocations
************************************************************************************
rename new_perm_water_area_share newpermwat_share
norm newpermwat_share, method(mmx)
norm perc_var_water, method(mmx)
drop newpermwat_share perc_var_water
lab var mmx_newpermwat_share "Proportion of sublocation area that is covered with newly permanent water"
lab var mmx_perc_var_water "Percent variation in water covered area (2022 vs 2015)"
*Spatially visualize variables
qui grmap, activate
//Average elevation
qui grmap mmx_elevation, title("Baringo county", size(*0.8)) subtitle("Average normalized elevation",size(*0.6))  fcolor(BuYlRd) legstyle(3) cln(4) legtitle(Variable) legenda(on) legend(ring(1) position(2)) 
qui graph export "${gsdOutput}/avg_elevation.jpg", as(jpg) quality(100) name("Graph") replace
//Average share of new permanent water
grmap mmx_newpermwat_share, title("Baringo county", size(*0.8)) subtitle("Average normalized share of new permanent water",size(*0.6))  fcolor(BuYlRd) legstyle(3) cln(4) legtitle(Variable) legenda(on) legend(ring(1) position(2)) 
qui graph export "${gsdOutput}\avg_newpermwater.jpg", as(jpg) quality(100) name("Graph") replace
//Average social vulnerability score
grmap svi, title("Baringo county", size(*0.8)) subtitle("Average normalized SVI",size(*0.6))  fcolor(BuYlRd) legstyle(3) cln(4) legtitle(Variable) legenda(on) legend(ring(1) position(2)) 
qui graph export "${gsdOutput}\avg_svi.jpg", as(jpg) name("Graph") quality(100) replace
qui save "${gsdOutput}/baringo_dataset_mcda.dta", replace 

use "${gsdOutput}/baringo_dataset_mcda.dta", clear 
**# Define the criteria to be fed into the analysis (grouped by thematic area)
global natural mmx_newpermwat_share mmx_elevation //natural factors
global socioeconomic svi //socioeconomic factors
mdesc objectid_1 $natural $socioeconomic
foreach v of varlist $natural $socioeconomic {
	replace `v'=0.0000001 if mi(`v') | `v'<0.0000001
}
summ  $natural $socioeconomic
qui export excel objectid_1 $natural $socioeconomic using "${gsdDo}/topsis_criteria_baringo.xlsx", replace firstrow(variables)
mata: setheader("${gsdDo}/topsis_criteria_baringo.xlsx", "Sheet1")

**# Import and store weights and impact parameters (as per discussion in excel reference table)
qui import excel "${gsdDo}\topsis_setup_baringo.xlsx", sheet("Sheet1") firstrow clear
rename (Impact Weight) (impact weight)
qui export excel impact if !mi(impact) using "${gsdDo}\topsis_impact_baringo.xlsx", firstrow(variables) replace //impacts (gains or costs)
mata: setheader("${gsdDo}\topsis_impact_baringo.xlsx", "Sheet1")
qui export excel weight if !mi(weight) using "${gsdDo}\topsis_weight_baringo.xlsx", firstrow(variables) replace //weights
mata: setheader("${gsdDo}\topsis_weight_baringo.xlsx", "Sheet1")

**# Run geotopsis
qui rsource using "${gsdDo}\topsis_baringo.R", roptions("--vanilla") rpath("C:/PROGRA~1/R/R-42~1.2/bin/x64/R")

**# Import the results of the geotopsis 
qui import excel "${gsdOutput}/topsisoutcome_baringo.xlsx", sheet("Sheet1") firstrow clear
rename score geotopsis_score
merge 1:1 objectid_1 using "${gsdOutput}/baringo_dataset_mcda.dta",  nogen keep(3)
keeporder _ID _CX _CY objectid_1  geotopsis_score
norm geotopsis_score, method(mmx) //normalize topsis score (0 to 1)
xtile geotopsis_categories = mmx_geotopsis_score, nq(4) //create quartiles on normalized values

**# Visualize results on map
qui spset 
qui grmap, activate
grmap geotopsis_categories,  title("Geotopsis results", size(*0.8)) subtitle("Baringo sublocation",size(*0.6)) note("", size(*0.7)) fcolor(BuYlRd) legstyle(3) cln(4) legtitle(Normalized geotopsis quartile) legenda(on) legend(ring(1) position(2))
qui graph export "${gsdOutput}\topsis_baringo.jpg", as(jpg) name("Graph") quality(100) replace

**# Export attribute table, with codebook and the addition of the topsis score
lab var geotopsis_score "Geotopsis score"
lab var mmx_geotopsis_score "Normalized (0-1) Geotopsis score"
lab var geotopsis_categories "Normalized Geotopsis score quartiles"
qui iecodebook export using "${gsdOutput}/topsis_baringo.xlsx", replace 
qui export excel using "${gsdOutput}/topsis_baringo.xlsx", sheet("attribute_table") sheetreplace firstrow(variables)
import excel "${gsdOutput}/topsis_baringo.xlsx", sheet("survey") firstrow clear
qui export excel name label	type using "${gsdOutput}/topsis_baringo.xlsx", sheet("codebook") sheetreplace firstrow(variables)
import excel "${gsdOutput}/topsis_baringo.xlsx", sheet("attribute_table") firstrow clear
qui export excel using "${gsdOutput}/topsis_baringo.xlsx", sheet("attribute_table") sheetreplace firstrow(variables)
mata: setheader("${gsdOutput}/topsis_baringo.xlsx", "codebook")
mata: setheader("${gsdOutput}/topsis_baringo.xlsx", "attribute_table")
erase "${gsdOutput}/topsis_baringo.xlsx"

