clear all 
set gr off
set scheme white_tableau
* Emanuele moves a few datasets produced in Google earth engine to correct Gdrive folder
else if (inlist("${suser}","wb562201", "WB562201")) {
	qui copy "G:\My Drive\earthengine\kenya\baringo work/Baringo_dem_bysublocation.csv" "${gsdDataRaw}/Baringo_dem_bysublocation.csv", replace //DEM for elevation
	qui copy "G:\My Drive\earthengine\kenya\baringo work\Ndvi_sublocations_baringo_ts.csv" "${gsdDataRaw}/Ndvi_sublocations_baringo_ts.csv", replace //NDVI time series
	qui copy "G:\My Drive\earthengine\kenya\baringo work\Baringo_subloc_chirps_1983012023011.csv" "${gsdDataRaw}/Baringo_subloc_chirps_1983012023011.csv", replace //rain time series
	
qui cd "${gsdTemp}"
 spshape2dta "${gsdDataRaw}\shapes\study_sublocations_mcda_results.shp", replace //sublocations
qui cd "${gsdTemp}"
 spshape2dta "${gsdDataRaw}\shapes\study_sublocations_mcda_results_wgs84.shp", replace //sublocations
qui use "${gsdTemp}/study_sublocations_mcda_results_wgs84.dta", clear
rename (_CX _CY) (_CX_wgs84 _CY_wgs84)
qui save "${gsdTemp}/study_sublocations_mcda_results_wgs84.dta", replace 
}
  
*Start analysis 
qui cd "${gsdTemp}"
 spshape2dta "${gsdDataRaw}\household_count_wb_2016/sublocations_baringo.shp", replace //sublocations

**# Process DEM (sublocation-level average elevation values)
qui import delimited "${gsdDataRaw}/Baringo_dem_bysublocation.csv", clear
gduplicates drop objectid_1,force
rename mean elevation
lab var elevation "Sublocation average elevation"
qui save "${gsdTemp}/dem.dta", replace 

**# Process census 2019 household level data
*1) Retrieve sublocation variable for linking census data and shapefile
use "${gsdDataRaw}\census 2019/Baringo 2019TenPercent_Population and Household Modules.dta", clear 
gduplicates drop COUNTY subcounty_code divisionname_code locationname_code sublocation_code EA STRNUMBER HHNUMBER, force
qui export excel COUNTY subcounty_code divisionname_code locationname_code sublocation_code EA STRNUMBER HHNUMBER LISTING_GPS_LATITUDE LISTING_GPS_LONGITUDE using "${gsdTemp}\hh_census2019.xls", firstrow(variables) nolabel replace
qui cd "${gsdTemp}"
qui spshape2dta "${gsdDataRaw}\census 2019/hh_2019_census_sublocationinfo.shp", replace //sublocations
use "${gsdTemp}/hh_2019_census_sublocationinfo.dta", clear 
rename (OBJECTID_1 subcounty_ divisionna locationna sublocatio) (objectid_1 subcounty_code divisionname_code locationname_code sublocation_code)
tempfile hh_2019_census_sublocationinfo
qui save `hh_2019_census_sublocationinfo', replace
use "${gsdDataRaw}\census 2019/Baringo 2019TenPercent_Population and Household Modules.dta", clear 
merge m:1 subcounty_code divisionname_code locationname_code sublocation_code EA STRNUMBER HHNUMBER using `hh_2019_census_sublocationinfo', keepusing(objectid_1) keep(3) nogen
egen hhid=group(subcounty_code divisionname_code locationname_code sublocation_code EA STRNUMBER HHNUMBER)
merge m:1 objectid_1 using "${gsdDataRaw}/popvars.dta", nogen keep(3) keepusing(area_sqkm) //sublocations area
keep if inlist(objectid_1, 4695,	4697,	4698,	4699,	4700,	4701,	4702,	4703,	4704,	4705,	4706,	4707,	4708,	4709,	4710,	4711,	4714,	4715,	4716,	4718,	4719,	4720,	4721,	4722,	4723,	4724,	4728,	4729,	4730,	4750,	4752,	4771,	4805,	4806,	4807,	4808,	4809,	4810,	4811,	4813,	4864,	4867,	4868,	4872,	4873,	4879,	4880,	4881,	4889,	4890,	4891,	4892,	4893,	4899,	4900)
qui format %14.0g sublocation_code
bys COUNTY subcounty_code divisionname_code locationname_code sublocation_code EA STRNUMBER HHNUMBER: gen hhsize=_N
egen n_eas = nvals(EA), by(sublocation_code)
lab var n_eas "Number of EAs (villages) in sublocation"
qui save "${gsdTemp}/sublocations_censusdata.dta", replace

*2) Construct socio-economic variables 

*Population count by sublocation
bys objectid_1: egen tot_population_bysl=count(objectid_1)

*Dependency ratio 
gen below15=(P12>=0 & P12<15)
gen above65=(P12>=65) & !mi(P12)
gen between_15_64=(P12>=15 & P12<65) 
bys hhid: egen totbelow15=total(below15)
bys hhid: egen totbetween_15_64=total(between_15_64)
bys hhid: egen totabove65=total(above65)
bys hhid: gen tot_hh_members=_N
gen hh_depshare=((totbelow15+totabove65)/tot_hh_members)
lab var hh_depshare "Household share of dependent people"

*Disability ratio
forval i=1/6 {
	gen P42_`i'_yn=inlist(P42_`i',2,3,4)
}
egen number_disabilitites=rowtotal(P42_*_yn),m
gen disable=number_disabilitites>0 & !mi(number_disabilitites)
bys hhid: egen tot_disable=total(disable)
gen hh_disableshare=tot_disable/tot_hh_members
lab var hh_disableshare "Household share of disable people"

*Household head is female
gen hhh_female=P10==1 & P11==2
*Household head is employed 
gen hhh_unemployed=mi(P50) & P10==1
*Education level
recode P46A (1 3 7 9 =1) (4 =2) (5 6= 3), gen(education)
*Use of telcom score
egen telcom_score=rowtotal(P55 P57 P58)
replace telcom_score=0 if telcom_score>3
*Asset index 
foreach v of varlist H39_1 H39_2 H39_3 H39_4 H39_5 H39_6 H39_7 H39_8 H39_9 H39_10 H39_11 H39_12 H39_13 H39_14 H39_15 H39_16 H39_17 H39_18 H39_19 {
	qui replace `v'=0 if `v'==2
}
qui pca H39_1 H39_2 H39_3 H39_4 H39_5 H39_6 H39_7 H39_8 H39_9 H39_10 H39_11 H39_12 H39_13 H39_14 H39_15 H39_16 H39_17 H39_18 H39_19, components(3)
qui predict asset_index_pca, score
qui norm asset_index_pca,method(mmx)
*N. cattle owned 
qui egen number_cattle=rowtotal(H26_1A H26_2A H26_3A H26_4A H26_5A H26_6A H26_7A H26_8A H26_9A H26_10A H26_11A H26_12 H26_12A H26_15A H30)
*Dwelling characterisctics 
//Roof 
qui recode H30 (2 3 4 12 =1) (5 6 7 =2) (8 9 10 19 11 12= 3), gen(roof)
fre roof
//Wall
qui recode H31 (2 3 4 16 =1) (5 6 7 8 9 10 =2) (11 12 13 14 15 17= 3), gen(wall)
fre wall
//Floor
qui recode H32 (1 2 3 =1) (4 5 6 =2) (7 8 9= 3), gen(floor)
fre floor
//Drinking water source 
qui recode H33 (1 2 3 4 6 8=1) (5 7 9 13 15=2) (10 11 12 14= 3), gen(drinkwatersource)
fre drinkwatersource
//Toilet type 
qui recode H34 (8 1 6 3 7=1) (2 5 4 =2) (9= 3), gen(toilettype)
fre toilettype
//Type of cooking fuel
qui recode H37 (5 6=1) (2 7 =2) (3 4 1= 3), gen(cookingfuel)
fre cookingfuel
//Type of lighting fuel 
qui recode H38 (10 6 =1) (2 3 4 5 7 8 9 11 13 =2) (1= 3), gen(lightingfuel)
fre lightingfuel
*Flag subsistence farming household
qui gen subsistence_farming=H20==1
clonevar n_rooms=H28
*Flag poor household
qui gen hh_poor=inlist(CENSUS_WEALTH_QUINTILE,1,2)

*3) Collapse dataset at household level
keep if P10==1
qui gduplicates drop hhid,force

*Population density by sublocation
qui gen population_density_bysl=tot_population_bysl/area_sqkm
qui norm population_density_bysl, method(mmx)

*If missing hh head education, assume primary 
replace education=1 if mi(education)

qui save "${gsdTemp}\hh_variables.dta", replace 

*5) Collapse indicators at sublocation level
gcollapse mmx_population_density_bysl hh_depshare hhh_unemployed education n_rooms telcom_score number_cattle roof wall floor drinkwatersource toilettype cookingfuel lightingfuel CENSUS_WEALTH_QUINTILE population_density_bysl hhh_female subsistence_farming hh_disableshare hh_poor H39_1 H39_2 H39_3 H39_4 H39_5 H39_6 H39_7 H39_8 H39_9 H39_10 H39_11 H39_12 H39_13 H39_14 H39_15 H39_16 H39_17 H39_18 H39_19, by(objectid_1)
mdesc *

**# Include roads density and include it in the sublocation-level dataset 
preserve 
qui import excel "${gsdDataRaw}\roads_density.xlsx", sheet("Sheet1") firstrow clear
renvars *, lower
lab var roadkm_km2 "Road density (km/km2)"
qui save "${gsdTemp}\roads_density.dta", replace
restore 
merge 1:1 objectid_1 using "${gsdTemp}\roads_density.dta", keepusing(roadkm_km2 shape_area)  nogen keep(1 3)
mdesc 
foreach v of varlist roadkm_km2 hh_depshare hh_disableshare hhh_female hhh_unemployed hh_poor subsistence_farming {
	qui norm `v', method(mmx)
}

//Exposure
global exposure mmx_population_density_bysl mmx_roadkm_km2

//Susceptibility
global susceptibility mmx_hh_depshare mmx_hh_disableshare mmx_hhh_female mmx_hhh_unemployed mmx_hh_poor mmx_subsistence_farming

//Adaptability
*Dwelling quality
pca n_rooms roof wall floor drinkwatersource toilettype cookingfuel lightingfuel, components(2)
predict dwelling_quality, score
norm dwelling_quality,method(mmx)

*Asset ownership 
qui pca H39_1 H39_2 H39_3 H39_4 H39_5 H39_6 H39_7 H39_8 H39_9 H39_10 H39_11 H39_12 H39_13 H39_14 H39_15 H39_16 H39_17 H39_18 H39_19, components(3)
qui predict asset_ownership, score
qui norm asset_ownership,method(mmx)

*Education 
qui norm education,method(mmx)

global adaptability mmx_dwelling_quality mmx_asset_ownership mmx_education

summ $exposure $susceptibility $adaptability
mdesc $exposure $susceptibility $adaptability
foreach v of varlist $exposure $susceptibility $adaptability {
	qui replace `v'=.00001 if `v'<.00001
}
qui savesome objectid_1 $exposure $susceptibility $adaptability using  "${gsdTemp}\svi_criteria.dta", replace

**# Implement the TOPSIS algorithm for computing the social vulnerability index (SVI)

*1) Define the weights for each criterion 
global weight_popdens 0.165 //Population density (n. people per km2)
global weight_roadens 0.165 //Road density (km of roads per km2)
global weight_depshare 0.055 //Share of household members not in working age (<15 or >65 years)
global weight_disableshare 0.055 //Share of household members with at least one impairment
global weight_hhhfemale 0.055 //Female household head
global weight_hhhunempl 0.055 //Unemployed household head
global weight_hhpoor 0.055 //Poor household
global weight_substfarm 0.055 //Household practices subsistence farming
global weight_dwellqual 0.11 //Housing conditions
global weight_hhheduc 0.11 //Education level of household head
global weight_asset 0.11 //Asset endowment

*2) Create the weighted criteria
qui gen wtd_mmx_pop_dens_bysl = mmx_population_density_bysl * $weight_popdens
qui gen wtd_mmx_roadkm_km2 = mmx_roadkm_km2 * $weight_roadens
qui gen wtd_mmx_hh_depshare = mmx_hh_depshare * $weight_depshare
qui gen wtd_mmx_hh_disableshare = mmx_hh_disableshare * $weight_disableshare
qui gen wtd_mmx_hhh_female = mmx_hhh_female * $weight_hhhfemale
qui gen wtd_mmx_hhh_unemployed = mmx_hhh_unemployed * $weight_hhhunempl
qui gen wtd_mmx_hh_poor = mmx_hh_poor * $weight_hhpoor
qui gen wtd_mmx_subsistence_farming = mmx_subsistence_farming * $weight_substfarm
qui gen wtd_mmx_dwelling_quality = mmx_dwelling_quality * $weight_dwellqual
qui gen wtd_mmx_education = mmx_education * $weight_hhheduc
qui gen wtd_mmx_asset_ownership = mmx_asset_ownership * $weight_asset								
*3) Create positive ideal values for each criterion with vulnerability increasing impact (+)
foreach v of varlist wtd_mmx_pop_dens_bysl wtd_mmx_roadkm_km2 wtd_mmx_hh_depshare wtd_mmx_hh_disableshare wtd_mmx_hhh_female wtd_mmx_hhh_unemployed wtd_mmx_hh_poor wtd_mmx_subsistence_farming {
	qui egen pi_`v'=max(`v')
}
*4) Create negative ideal values for each criterion with vulnerability decreasing impact (-)
foreach v of varlist wtd_mmx_dwelling_quality wtd_mmx_education wtd_mmx_asset_ownership {
	qui egen ni_`v'=max(`v')
}
*5) Compute distances to ideal (both positive and negative ideals)
qui gen distance_to_ideal_var1 = sqrt((wtd_mmx_pop_dens_bysl - pi_wtd_mmx_pop_dens_bysl)^2 + (wtd_mmx_roadkm_km2 - pi_wtd_mmx_roadkm_km2)^2 + (wtd_mmx_hh_depshare - pi_wtd_mmx_hh_depshare)^2 + (wtd_mmx_hh_disableshare - pi_wtd_mmx_hh_disableshare)^2 + (wtd_mmx_hhh_female - pi_wtd_mmx_hhh_female)^2 + (wtd_mmx_hhh_unemployed - pi_wtd_mmx_hhh_unemployed)^2 + (wtd_mmx_hh_poor - pi_wtd_mmx_hh_poor)^2 + (wtd_mmx_subsistence_farming - pi_wtd_mmx_subsistence_farming)^2)
qui gen distance_to_negative_ideal_var1 = sqrt((wtd_mmx_dwelling_quality - ni_wtd_mmx_dwelling_quality)^2 + (wtd_mmx_education - ni_wtd_mmx_education)^2 + (wtd_mmx_asset_ownership - ni_wtd_mmx_asset_ownership)^2 )
*6) Compute topsis score 
qui gen svitopsis_score = distance_to_negative_ideal_var1 / (distance_to_ideal_var1 + distance_to_negative_ideal_var1)
replace svitopsis_score=1/svitopsis_score

*Normalize result between 0 and 1
qui norm svitopsis_score, method(mmx)

rename mmx_svitopsis_score svi
clonevar OBJECTID_1=objectid_1
merge 1:1 OBJECTID_1 using "${gsdTemp}/study_sublocations_mcda_results.dta",keepusing(FIRST_SLNA) keep(1 3) nogen assert(1 3)
qui export excel using "${gsdOutput}\svi_mcda_results.xls", sheetreplace firstrow(variables) nolabel
qui save "${gsdTemp}/svi.dta", replace 

xtile sviq = svi, nq(4)
lab def sviq 1 "Quartile 1" 2 "Quartile 2" 3 "Quartile 3" 4 "Quartile 4"
lab val sviq sviq
*Graph with average values of SVI by quartile
forval i=1/4 {
	qui summ svi if sviq==`i'
	local min_`i': display %4.3f `r(min)'
	local max_`i': display %4.3f `r(max)'
}
qui betterbarci svi, over(sviq) n  bar format(%9.2f) title("Normalized SVI score") subtitle("By SVI Quartile") xtitle("Quartile")  xscale(off) ylabel(#5) ytitle("Average score") barc(red orange yellow green) v note("Range for Q1 is: `min_1' - `max_1';" "Range for Q2 is: `min_2' - `max_2';" "Range for Q3 is: `min_3' - `max_3';"  "Range for Q4 is: `min_4' - `max_4'") ylab(, nogrid)
qui graph export "${gsdOutput}\svi_byquartile.jpg", as(jpg) name("Graph") quality(100) replace 
bys sviq: asdoc sum svi, stat(N mean min max semean) saving(${gsdTemp}\svi_byqrt.docx) replace 
bys sviq: asdoc sum mmx_*, stat(mean) saving(${gsdTemp}\svi_params.docx) replace 
asdoc sum wtd_*, stat(mean) saving(${gsdTemp}\svi_params_wgt.docx) by(sviq) replace format(%9.3f) 


**# Get area covered by water between 2003 and 2023. Compute the variation btw years and normalize it by sublocation total area. Data on water cover taken from Landsat 7 and 8 via Google Earth Engine
qui import excel "${gsdDataRaw}\water_extent_bysl_20032023.xlsx", sheet("Foglio2") firstrow clear
dropmiss *, force
drop if mi(sublocation)
split sublocation,p("_")
rename sublocation2 objectid_1
destring objectid_1, replace 
merge 1:1 objectid_1 using "${gsdTemp}\roads_density", keepusing(shape_area)  nogen keep(3)
gen water_prop_2003=extent_2003/(shape_area/1000000)
gen water_prop_2023=extent_2023/(shape_area/1000000)
gen new_perm_water_area_share=(water_prop_2023/water_prop_2003)-1
replace new_perm_water_area_share=0 if mi(new_perm_water_area_share)
lab var new_perm_water_area_share "Percent variation in new water within each sublocation. Normalized by sublocation area"
keeporder sublocation objectid_1 extent_2003 extent_2023 shape_area water_prop_2003 water_prop_2023 new_perm_water_area_share
qui save "${gsdTemp}/new_permanentwater.dta", replace 
qui import excel "${gsdDataRaw}\water_extent_years.xlsx", sheet("Sheet1") firstrow clear
rename year objectid_1
replace objectid_1 = subinstr(objectid_1,"sl","",.)
qui destring objectid_1, replace 
qui drop if mi(objectid_1)
clonevar OBJECTID_1=objectid_1
merge 1:1 OBJECTID_1 using "${gsdTemp}/study_sublocations_mcda_results_wgs84.dta", keepusing(FIRST_SLNA)  nogen keep(3)
forval y=2004/2024 {
	local prevyear=`y'-1
	cap gen perc_diff_ext_`y'_vs_`prevyear'=((extent_`y'/extent_`prevyear')-1)
}
egen avg_acceleration_flood=rowmean(perc_diff_ext_*)
lab var avg_acceleration_flood "Average year to year % variation in water land cover"
tempfile avg_acceleration_flood
qui save "${gsdTemp}/avg_acceleration_flood.dta", replace 
qui reshape long extent_,i(objectid_1) j(year)
merge m:1 objectid_1 using "${gsdTemp}\roads_density", keepusing(shape_area)  nogen keep(1 3)
qui gen water_prop=(extent_/(shape_area/1000000))*100
twoway (line water_prop year), ytitle(`"% of sublocation's surface"') xtitle(`"Year"') by(, title(`"Yearly trend in water cover"')) by(FIRST_SLNA)
qui graph export "${gsdOutput}\trend_water_bysloc.png", as(png) name("Graph") replace
qui save "${gsdTemp}\water_byyear_sloc_long.dta", replace 
bys year: egen tot_waterarea=total(extent_)
qui gduplicates drop year,force
tostring year, gen(y)
gen m="01"
gen d="01"
gen imageid=y+m+d
qui destring imageid, replace
tempfile water_ts
qui save `water_ts', replace 

**# Process NDVI time series 
qui import delimited "${gsdDataRaw}/Ndvi_sublocations_baringo_ts.csv", clear
split imageid,p("_")
drop imageid
destring imageid3,gen(imageid)
clonevar imageid_s=imageid3
// rename imageid imageid_s
// gen imageid = subinstr(imageid_s,"_","",.)
// destring imageid, replace force
order objectid_1 imageid_s imageid mean
rename mean ndvi
duplicates drop objectid_1 imageid, force
tempfile ndvi_ts
qui save `ndvi_ts', replace 

**# Process rainfall variables 
set gr on
** Import CHIPRS long term averages and sd data (sensor-level daily values retrieved via Google Earth Engine API: https://code.earthengine.google.com/cc54cb03160cc5de5f14a50f33906caf)
qui import delimited "G:\My Drive\earthengine\kenya\baringo work\Baringo_subloc_chirps_1983012023011.csv", clear 
merge 1:1 objectid_1 imageid using `ndvi_ts', keepusing(ndvi) keep(1 3) nogen
merge 1:1 objectid_1 imageid using `water_ts', keepusing(tot_waterarea) keep(1 3) nogen

//keep if imageid>20030101 //restrict data from 2003 for time span comparability 
//keep if inlist(objectid_1,4700,	4701,	4702	,4719	,4720	4752	,4771	,4805,	4806,	4808	,4809,	4810)
keep if inlist(objectid_1, 4695,	4697,	4698,	4699,	4700,	4701,	4702,	4703,	4704,	4705,	4706,	4707,	4708,	4709,	4710,	4711,	4714,	4715,	4716,	4718,	4719,	4720,	4721,	4722,	4723,	4724,	4728,	4729,	4730,	4750,	4752,	4771,	4805,	4806,	4807,	4808,	4809,	4810,	4811,	4813,	4864,	4867,	4868,	4872,	4873,	4879,	4880,	4881,	4889,	4890,	4891,	4892,	4893,	4899,	4900)

qui tostring imageid,gen(imageids)
qui gen y=substr(imageids,1,4)
qui gen m=substr(imageids,5,2)
destring y, replace
clonevar year=y
gen OBJECTID_1=objectid_1
merge m:1 OBJECTID_1 using "${gsdTemp}/study_sublocations_mcda_results_wgs84.dta", keepusing(FIRST_SLNA)  nogen keep(3)
*Create graph to visualize the yearly water surface covered by water, and the rainfall
preserve 
collapse (sum) mean (mean) ndvi,by(FIRST_SLNA objectid_1 year)
merge 1:1 objectid_1 year using "${gsdTemp}\water_byyear_sloc_long.dta", keep(3) nogen
lab var water_prop "Percentage"
lab var mean "Milliliters"
//replace ndvi=. if ndvi<0
//twoway line water_prop year, yaxis(1) || line mean year, yaxis(2) || line ndvi year, yaxis(1)  by(objectid_1) legend(order(1 "Proportion of land surface covered by water" 3 "Total rainfall" 2 "NDVI"))
clonevar sublocation_id=objectid_1
twoway line water_prop year, yaxis(1) || line mean year, yaxis(2)  by(FIRST_SLNA) legend(order(1 "Proportion of land surface covered by water (%)" 2 "Total rainfall (mm)"))
qui graph export "${gsdOutput}\trend_rain&water_bysloc.png", as(png) name("Graph") replace
restore 
collapse (sum) mean (mean) ndvi (max) tot_waterarea y, by(imageid)
//keep if inlist(m,"03", "04", "05", "10", "11", "12") //restrict to rainy season
collapse (sum) mean (mean) ndvi (max) tot_waterarea, by(y) 
xtset y
multiline mean ndvi tot_waterarea y, recast(connected) xlabel(2003(5)2023) xtitle(`"Year"') 
*Show time trend for rainfall
rename mean rain
qui reg rain y 
predict rain_h, xb
lab var rain "Total annual rainfall"
lab var rain_h "Trend line"
qui ktau y rain 
twoway (line rain y) (line rain_h y, lcolor(lime)), ytitle(`"MM"', size(vsmall)) ylabel(#3, labsize(vsmall)) xtitle(`"Year"', size(vsmall)) xlabel(1983(5)2023, labsize(vsmall)) title(`"Cumulative average rainfall"') caption(`"Kendall Trend test p-value: `r(p)'"', size(vsmall)) saving("${gsdTemp}/rain_ts", replace)
qui graph export "${gsdTemp}\cum_rain_ts_baringo.png", as(png) name("Graph") replace
*Show time trend for NDVI
qui reg ndvi y 
predict ndvi_h, xb
lab var ndvi "NDVI"
lab var ndvi_h "Trend line"
qui ktau y ndvi 
twoway (line ndvi y ) (line ndvi_h y, lcolor(lime)) if y>2002, ytitle(`"NDVI"', size(vsmall)) ylabel(#4, labsize(vsmall)) xtitle(`"Year"', size(vsmall)) xlabel(2003(5)2023, labsize(vsmall)) title(`"Average NDVI"') caption(`"Kendall Trend test p-value: `r(p)'"', size(vsmall)) saving("${gsdTemp}/ndvi_ts", replace)
qui graph export "${gsdTemp}\avg_ndvi_ts_baringo.png", as(png) name("Graph") replace
*Show time trend for water surface
qui reg tot_waterarea y 
predict tot_waterarea_h, xb
lab var tot_waterarea "Water surface"
lab var tot_waterarea_h "Trend line"
qui ktau y tot_waterarea 
twoway (line tot_waterarea y) (line tot_waterarea_h y, lcolor(lime)) if y>2002, ytitle(`"Area km2"', size(small)) ylabel(#4, labsize(vsmall)) xtitle(`"Year"', size(vsmall)) xlabel(2003(5)2023, labsize(vsmall)) title(`"Water surface"') caption(`"Kendall Trend test p-value: `r(p)'"', size(vsmall)) saving("${gsdTemp}/watersurface_ts", replace)
qui graph export "${gsdTemp}\avg_watersurface_ts_baringo.png", as(png) name("Graph") replace
*Combine graph for rain and ndvi
qui gr combine rain_ts.gph ndvi_ts.gph watersurface_ts.gph 
qui graph export "${gsdOutput}\trendgraph_combined.png", as(png) name("Graph") replace
set gr on 

**# Build dataset for MCDA
use "${gsdTemp}/sublocations_baringo.dta",clear 
rename OBJECTID_1 objectid_1
keep if inlist(objectid_1, 4695,	4697,	4698,	4699,	4700,	4701,	4702,	4703,	4704,	4705,	4706,	4707,	4708,	4709,	4710,	4711,	4714,	4715,	4716,	4718,	4719,	4720,	4721,	4722,	4723,	4724,	4728,	4729,	4730,	4750,	4752,	4771,	4805,	4806,	4807,	4808,	4809,	4810,	4811,	4813,	4864,	4867,	4868,	4872,	4873,	4879,	4880,	4881,	4889,	4890,	4891,	4892,	4893,	4899,	4900)
merge 1:1 objectid_1 using "${gsdTemp}/dem.dta", nogen keep(3) keepusing(elevation) //merge average elevation
merge 1:1 objectid_1 using "${gsdTemp}/svi.dta", nogen keep(1 3)  keepusing(svi $exposure $susceptibility $adaptability) //socio-economic indicators from the 2019 census
merge 1:1 objectid_1 using "${gsdTemp}/new_permanentwater.dta", nogen keep(1 3) keepusing(new_perm_water_area_share extent_2003 extent_2023) //proportion of sublocation surface that is newly permanent waters
merge 1:1 objectid_1 using "${gsdTemp}/avg_acceleration_flood.dta",keepusing(avg_acceleration_flood) keep(1 3) nogen 
keeporder _ID _CX _CY objectid_1 elevation new_perm_water_area_share extent_2003 extent_2023 svi $exposure $susceptibility $adaptability avg_acceleration_flood FIRST_LOCN FIRST_SLNA 
norm elevation, method(mmx)

norm avg_acceleration_flood, method(mmx)
gen weight_watshare=mmx_avg_acceleration_flood+1 
replace weight_watshare=1 if mi(weight_watshare)
// br objectid_1 new_perm_water_area_share avg_acceleration_flood weight_watshare

************************************************************************************
**# Setup topsis on Baringo sublocations
************************************************************************************
rename new_perm_water_area_share newpermwat_share
norm newpermwat_share, method(mmx)
lab var mmx_newpermwat_share "Proportion of sublocation area that is covered with newly permanent water (0-1 normalized value)"

*Spatially visualize variables
qui grmap, activate
//Average elevation
qui grmap mmx_elevation, title("Baringo county", size(*0.8)) subtitle("Average normalized elevation",size(*0.6))  fcolor(BuYlRd) legstyle(3) cln(4) legtitle(Variable) legenda(on) legend(ring(1) position(2)) 
qui graph export "${gsdOutput}/avg_elevation.jpg", as(jpg) quality(100) name("Graph") replace
//Average share of new permanent water
grmap mmx_newpermwat_share, title("Baringo county", size(*0.8)) subtitle("Average normalized share of new permanent water",size(*0.6))  fcolor(BuYlRd) legstyle(3) cln(4) legtitle(Variable) legenda(on) legend(ring(1) position(2)) 
qui graph export "${gsdOutput}\avg_newpermwater.jpg", as(jpg) quality(100) name("Graph") replace
//Average social vulnerability score
grmap svi, title("Baringo county", size(*0.8)) subtitle("Average normalized SVI",size(*0.6))  fcolor(BuYlRd) legstyle(3) cln(4) legtitle(Variable) legenda(on) legend(ring(1) position(2)) 
qui graph export "${gsdOutput}\avg_svi.jpg", as(jpg) name("Graph") quality(100) replace
qui save "${gsdOutput}/baringo_dataset_mcda.dta", replace 

use "${gsdOutput}/baringo_dataset_mcda.dta", clear
clonevar OBJECTID_1=objectid_1
merge 1:1 OBJECTID_1 using "${gsdTemp}/study_sublocations_mcda_results.dta",keepusing(FIRST_SLNA) keep(1 3) nogen assert(1 3) 
**# Define the criteria to be fed into the analysis (grouped by thematic area)
global natural mmx_elevation mmx_newpermwat_share
global socioeconomic svi
qui mdesc objectid_1 $natural $socioeconomic
assert `r(percent)' ==  0
foreach v of varlist $natural $socioeconomic {
	replace `v'=0.0000001 if mi(`v') | `v'<0.0000001
}
summ  $natural $socioeconomic

**# Implement the TOPSIS algorithm 

*1) Define the weights for each criterion (for sensitivity analysis, change parameters in the globals) 
global weight_elevation .25
global weight_water .25
global weight_svi .5
*2) Create the weighted criteria
gen weighted_mmx_elevation = mmx_elevation * $weight_elevation
gen weighted_mmx_newpermwat_share = mmx_newpermwat_share * $weight_water //*weight_watshare (could further weigh this by the average acceleration of the phenomenon in each sublocation. Don't apply to the analysis for this paper but suggest in the discussion section possibly).
gen weighted_svi = svi * $weight_svi
*3) Create positive ideal values for each criterion with vulnerability increasing impact (+)
egen ideal_weighted_mmx_water = max(weighted_mmx_newpermwat_share)
egen ideal_svi = max(weighted_svi)
*4) Create negative ideal values for each criterion with vulnerability decreasing impact (-)
egen negative_ideal_elevation = min(weighted_mmx_elevation) //higher elevation decreases the risk
*5) Compute distances to ideal (both positive and negative ideals)
gen distance_to_ideal_var1 = sqrt((weighted_mmx_newpermwat_share - ideal_weighted_mmx_water)^2 + (weighted_svi - ideal_svi)^2 )
gen distance_to_negative_ideal_var1 = sqrt((weighted_mmx_elevation - negative_ideal_elevation)^2 )
*6) Compute topsis score 
gen geotopsis_score = distance_to_negative_ideal_var1 / (distance_to_ideal_var1 + distance_to_negative_ideal_var1)
*7) Normalize topsis score
replace geotopsis_score=.001 if geotopsis_score==0
replace geotopsis_score=1/geotopsis_score
norm geotopsis_score,method(mmx)
*8 Create quartiles for the topsis scores
xtile geotopsis_categories = mmx_geotopsis_score, nq(4) 
*9) Visualize topsis results on the map
qui grmap, activate
qui grmap geotopsis_categories, title("Prioritization of sublocations", size(*0.8)) subtitle("Baringo and Bogoria sublocations",size(*0.6))  fcolor(RdYlGn) legstyle(3) cln(4) legtitle(Variable) legenda(on) legend(ring(1) position(2)) 
lab def geotopsis_categories 1 "Low priority" 2 "Medium priority" 3 "High priority" 4 "Highest priority"
lab val geotopsis_categories geotopsis_categories
qui graph export "${gsdOutput}\topsis_baringo.jpg", as(jpg) name("Graph") quality(100) replace

*Graph with average values of Overall vulnerability score by quartile
forval i=1/4 {
	qui summ mmx_geotopsis_score if geotopsis_categories==`i'
	local min_`i': display %4.3f `r(min)'
	local max_`i': display %4.3f `r(max)'
}
qui betterbarci mmx_geotopsis_score, over(geotopsis_categories) n  bar format(%9.2f) title("Normalized overall vulnerability score") subtitle("By priority class") xtitle("Quartile")  xscale(off) ylabel(#5) ytitle("Average score") barc(red orange yellow green) v note("Range for Q1 is: `min_1' - `max_1';" "Range for Q2 is: `min_2' - `max_2';" "Range for Q3 is: `min_3' - `max_3';"  "Range for Q4 is: `min_4' - `max_4'") ylab(, nogrid) saving("${gsdTemp}/cibar_topsis", replace) legend(size(vsmall))
qui graph export "${gsdOutput}\vulnerability_byquartile.jpg", as(jpg) name("Graph") quality(100) replace 
graph hbar (mean) mmx_geotopsis_score, over(FIRST_SLNA, sort(mmx_geotopsis_score) label(labsize(vsmall))) nofill cw by(geotopsis_categories) saving("${gsdTemp}/hbar_topsis", replace) ytitle("Overall vulnerability score")
qui graph export "${gsdOutput}\vulnerabilityscore_byquartile.jpg", as(jpg) name("Graph") quality(100) replace 
qui gr combine cibar_topsis.gph hbar_topsis.gph
qui graph export "${gsdOutput}\vulnerability_quartiles.jpg", as(jpg) name("Graph") quality(100) replace 
qui graph export "${gsdOutput}\overallvuln_graph.png", as(png) name("Graph") replace
lab var weighted_mmx_elevation "Weighted normalized elevation"
lab var weighted_mmx_newpermwat_share "Weighted normalized new water %"
lab var weighted_svi "Weighted normalized SVI"
lab var mmx_geotopsis_score "Normalized distance from ideal"
sort geotopsis_categories
gen geotopsis_categories1=geotopsis_categories
qui asdoc sum weighted_mmx_elevation weighted_mmx_newpermwat_share weighted_svi mmx_geotopsis_score, stat(N mean semean min max) save(${gsdOutput}\overall_vuln_score_table.doc) replace by(geotopsis_categories1) hide label

qui save "${gsdOutput}/baringo_mcda_results.dta", replace 

**# Cost estimates of the intervention
*Retrieve and store the PPP conversion factor (for converting Ksh into 2022 PPP USD - latest value available for PPP is 2022)
// preserve
// clear all
// wbopendata, language(en - English) country(KEN) topics() indicator()
// keep if countryname=="Kenya" & indicatorcode =="PA.NUS.PRVT.PP"
// qui summ yr2022,d
// global ppp2022 `r(mean)'
// dis ${ppp2022}
// restore 
global usd_ksh 130 //${ppp2022} //define exchange rate PPP USD/Ksh

*Training costs
local sheets Sustainable_Mgmt Bamboo_Biz_chann furniture_training propagation Sustainable_Harv_and_MNGT
foreach s of local sheets {
	qui import excel "${gsdDataRaw}\sample budget.xlsx", sheet("`s'") firstrow clear
	qui dropmiss *, force
	egen `s'_ucd=total(Unitcost)
	replace `s'_ucd=`s'_ucd
	lab var `s'_ucd "Unit daily cost for `s'_ucd"
	gen id=1
	qui save "${gsdTemp}\budget_`s'.dta", replace 
}
use "${gsdTemp}\budget_Sustainable_Mgmt.dta",clear 
local sheets Sustainable_Mgmt Bamboo_Biz_chann furniture_training propagation Sustainable_Harv_and_MNGT
foreach s of local sheets {
	qui merge m:m id using "${gsdTemp}\budget_`s'.dta", nogen keepusing(`s'_ucd) assert(3) keep(3)
	erase "${gsdTemp}\budget_`s'.dta"
}
qui gduplicates drop id, force
keeporder id Bamboo_Biz_chann_ucd furniture_training_ucd propagation_ucd Sustainable_Harv_and_MNGT_ucd
*Unit costs for a plant of bamboo
gen bamboo_uc_plant_self=80
gen bamboo_uc_plant_nursery=150
global bamboo_uc_plant_self 80
global bamboo_uc_plant_nursery 150
lab var bamboo_uc_plant_self "Cost of one bamboo plant (self production)"
lab var bamboo_uc_plant_nursery "Cost of one bamboo plant (nursery procurement)"
qui save "${gsdOutput}\unit_cost_bamboo.dta", replace 

*Add bamboo activities costing information and export to attribute table (for shapefile join and QGIS maps)
use "${gsdOutput}/baringo_mcda_results.dta", clear 
gen id=1
qui merge m:1 id using "${gsdOutput}\unit_cost_bamboo.dta", nogen assert(3) keep(3)
qui merge m:m objectid_1 using "${gsdTemp}/sublocations_censusdata.dta", nogen keep(3) keepusing(divisionname_code locationname_code sublocation_code n_eas)
qui gduplicates drop objectid_1,force
qui export excel objectid_1 elevation mmx_elevation svi mmx_newpermwat_share newpermwat_share geotopsis_score geotopsis_categories mmx_geotopsis_score OBJECTID_1 using "${gsdOutput}/mcda_results.xls", sheetreplace firstrow(variables) nolabel sheet("Results")
preserve 
keep objectid_1 mmx_elevation svi mmx_newpermwat_share geotopsis_score geotopsis_categories mmx_geotopsis_score newpermwat_share
lab var mmx_elevation "Average sublocation elevation (0-1 normalized)"
lab var svi "Normalized (0-1) Social Vulnerability Index"
lab var geotopsis_score "Geotopsis score"
lab var mmx_geotopsis_score "Normalized (0-1) Geotopsis score"
qui iecodebook export  using "${gsdTemp}/codebook.xlsx", replace 
qui import excel "${gsdTemp}/\codebook.xlsx", sheet("survey") firstrow clear
rename name variablename
qui export excel variablename label type using "${gsdOutput}/mcda_results.xls", sheetreplace firstrow(variables) nolabel sheet("Codebook")
erase "${gsdTemp}/\codebook.xlsx"
restore

**# Cost for bamboo planting (unit cost*hectares suggested cfr shapefile)
preserve
qui cd "${gsdTemp}"
qui spshape2dta "${gsdDataRaw}\shapes\intervention_shapes/bamboo_embankments_bysloc.shp", replace //bamboo embankments
use "${gsdTemp}/bamboo_embankments_bysloc.dta",clear 
gen cost_bamboo=(400*ha_bamboo*$bamboo_uc_plant_nursery)/${usd_ksh} //there are 400 bamboo plants in one hectare. multiply that by the identified area and the price per plant (nursery prices)
collapse (sum) tot_cost_bambooplant=cost_bamboo (sum) tot_area_bambooplant=ha_bamboo, by(OBJECTID_1)
tempfile tot_cost_bambooplant
qui save `tot_cost_bambooplant', replace
restore 
**# Cost for reed planting (unit cost*hectares suggested cfr shapefile)
preserve 
qui cd "${gsdTemp}"
qui spshape2dta "${gsdDataRaw}\shapes\intervention_shapes/reed_bysloc.shp", replace // reeds
use "${gsdTemp}/reed_bysloc.dta",clear 
gen cost_reed=(750*reed_ha*100)/${usd_ksh} //there are 750 reed plants in one hectare. multiply that by the identified area and the price per plant i.e. 100 ksh (nursery prices)
bys OBJECTID_1: egen tot_cost_reedplant=total(cost_reed)
collapse (sum) tot_cost_reedplant=cost_reed (sum) tot_area_reedplant=reed_ha, by(OBJECTID_1)
tempfile tot_cost_reedplant
qui save `tot_cost_reedplant', replace
restore 

merge m:1 OBJECTID_1 using `tot_cost_bambooplant', nogen keepusing(tot_cost_bambooplant tot_area_bambooplant) //assert(3) keep(3)
merge m:1 OBJECTID_1 using `tot_cost_reedplant', nogen keepusing(tot_cost_reedplant tot_area_reedplant) //assert(3) keep(3)

gen cost_workshop=(Bamboo_Biz_chann_ucd+furniture_training_ucd +propagation_ucd+ Sustainable_Harv_and_MNGT_ucd)*3/$usd_ksh if geotopsis_categories==4 //at least 2 workshops per sublocation for logistics reasons

//cost of embankment is:
local unit_cost_meter 1500 //for a 5 meters high embankment, the meter unit cost is 1500 usd/m. source: https://assets.publishing.service.gov.uk/media/6034ed2ed3bf7f264f23eb51/Cost_estimation_for_fluvial_defences.pdf [page 12]
local meter_length 700+400 //loboi (700 meters) +waseges inlet (400 meters) front barrage
qui count if geotopsis_categories==4

merge 1:1 OBJECTID_1 using "${gsdTemp}/study_sublocations_mcda_results_wgs84.dta",keepusing(_CX_wgs84 _CY_wgs84) nogen keep(1 3) assert(1 3)
geodist _CX_wgs84 _CY_wgs84  36.06817 0.35422  if geotopsis_categories==4, gen(dist_slc_embkmt)
norm dist_slc_embkmt,method(mmx)
gen a=1 
bys a:egen tot_dist_slc_embkmt=sum(dist_slc_embkmt)
gen share_cost_emb=dist_slc_embkmt/tot_dist_slc_embkmt
total share_cost_emb
//gen cost_embankment=(`unit_cost_meter'*`meter_length')*(1/share_cost_emb) if geotopsis_categories==1 //tested a factor adjustment to the embankment cost (impute it proportionally to the distance from embankments as the closer the sublocation the more the beneefit)
count if geotopsis_categories==4
gen cost_embankment=(`unit_cost_meter'*`meter_length')/`r(N)' if geotopsis_categories==4
egen cost=rowtotal(cost_workshop tot_cost_bambooplant tot_cost_reedplant cost_embankment), m 
qui save "${gsdTemp}\cost_bysublocations.dta", replace 

**# Compute value of dwellings via hedonic model leveraging 2021 kchs
run "${gsdDo}\0-1-1-dwelling_val_estimate.do"

**# Compute value of agricultural activities using 2021 kchs labor data 
run "${gsdDo}\0-1-2-agri_laborval_estimate.do"

**# Divide the above by the estimated total cost of the intervention and get the CEA ratio
qui grmap, activate
use "${gsdTemp}\cost_bysublocations.dta", clear 
merge 1:1 objectid_1 using "${gsdTemp}\benefit_dwelling_bysublocations.dta", keepusing(hh_dwelling_value_y n_dwellings) nogen assert(3) keep(3)
merge 1:1 objectid_1 using "${gsdTemp}\benefit_income_bysublocations.dta", keepusing(income_value_y n_ppl_agric) nogen assert(3) keep(3)
replace hh_dwelling_value_y=. if mi(cost)
replace income_value_y=. if mi(cost)
gen benefit=hh_dwelling_value_y+income_value_y //Sum the 2 and get estimate of economic loss due to water invasion 
gen cea_dwellings=cost / n_dwellings
replace cea_dwellings=. if geotopsis_categories!=4
qui grmap cea_dwellings, title("Cost Effectiveness Analysis", size(*0.8)) subtitle("Cost for saving a dwelling",size(*0.6))  fcolor(BuYlRd) legstyle(3) cln(4) legtitle(Variable) legenda(on) legend(ring(1) position(2)) 
qui graph export "${gsdOutput}\cea_dwellings.jpg", as(jpg) name("Graph") quality(100) replace
*Sensitivity for dwelling CEA
foreach v of varlist cost n_dwellings {
	forval i=1/10 {
		qui gen `v'_`i'=runiform(`v'*(100-`i'),`v'*(100+`i'))
		qui replace `v'_`i'=`v'_`i'/100
	}
}
forval i=1/10 {
	qui gen cea_dwellings_bw`i'=cost_`i'/n_dwellings_`i'
	qui replace cea_dwellings_bw`i'=. if geotopsis_categories!=4
	lab var cea_dwellings_bw`i' "Bandwidth `i' %"
} 
encode FIRST_SLNA,gen(sloc_name)
betterbarci cea_dwellings_bw* if geotopsis_categories==4 , bar format(%9.0f)  ytitle("CEA Ratio oscillation badwidth") xtitle("CEA in USD") ylabel(, labsize(vsmall)) legend(off) saving(sensitivity_dwellings.gph, replace) title("Dwellings preservation", size(medium))
drop cost_1-cost_10 

gen cea_employedppl=cost / n_ppl_agric
replace cea_employedppl=. if geotopsis_categories!=4
qui grmap cea_employedppl, title("Cost Effectiveness Analysis", size(*0.8)) subtitle("Cost for saving an agrarian employment",size(*0.6))  fcolor(BuYlRd) legstyle(3) cln(4) legtitle(Variable) legenda(on) legend(ring(1) position(2)) 
qui graph export "${gsdOutput}\cea_employed.jpg", as(jpg) name("Graph") quality(100) replace

*Sensitivity for agrarian jobs CEA
foreach v of varlist cost n_ppl_agric {
	forval i=1/10 {
		qui gen `v'_`i'=runiform(`v'*(100-`i'),`v'*(100+`i'))
		qui replace `v'_`i'=`v'_`i'/100
	}
}
forval i=1/10 {
	qui gen cea_employedppl_bw`i'=cost_`i'/n_ppl_agric_`i'
	qui replace cea_employedppl_bw`i'=. if geotopsis_categories!=4
	lab var cea_employedppl_bw`i' "Bandwidth `i' %"
} 
betterbarci cea_employedppl_bw* if geotopsis_categories==4 , bar format(%9.0f)  ytitle("CEA Ratio oscillation badwidth") xtitle("CEA in USD") ylabel(, labsize(vsmall)) legend(off) saving(sensitivity_jobs.gph, replace)  title("Agrarian jobs preservation", size(medium))
qui graph combine sensitivity_dwellings.gph sensitivity_jobs.gph, ycommon xcommon title("CEA Sensitivity", size(medium))
qui graph export "${gsdOutput}\cea_sensitivity.jpg", as(jpg) name("Graph") quality(100) replace

bys geotopsis_categories: egen total_cost=sum(cost)
bys geotopsis_categories: egen total_n_ppl_agric=sum(n_ppl_agric)
bys geotopsis_categories: egen total_n_dwellings=sum(n_dwellings)
qui export excel OBJECTID_1 total_cost total_n_ppl_agric total_n_dwellings cea_dwellings cea_employedppl using "${gsdTemp}\cea_vars.xls", firstrow(variables) replace

merge m:1 OBJECTID_1 using `tot_cost_bambooplant', nogen keepusing(tot_cost_bambooplant tot_area_bambooplant) //assert(3) keep(3)
merge m:1 OBJECTID_1 using `tot_cost_reedplant', nogen keepusing(tot_cost_reedplant tot_area_reedplant) //assert(3) keep(3)
merge 1:1 OBJECTID_1 using "${gsdTemp}/sublocations_baringo.dta", nogen keepusing(ha_sloc) //assert(3) keep(3)

gen bamboo_plant_density=tot_area_bambooplant/ha_sloc*100
lab var bamboo_plant_density "Bamboo plantation density"
gen reed_plant_density=tot_area_reedplant/ha_sloc*100
lab var reed_plant_density "Reed plantation density"

bys FIRST_SLNA: asdoc sum cost cost_embankment cost_workshop tot_cost_bambooplant tot_cost_reedplant tot_area_bambooplant tot_area_reedplant bamboo_plant_density reed_plant_density if geotopsis_categories==4, stat(mean) saving(${gsdTemp}\cea_costs.docx) replace 

*Show results of overall CEA (compounding the values for all the 13 sublocations of intervention)
qui total cost if geotopsis_categories==4 
qui matrix list e(b)
local num=e(b)[1,1]
qui total n_dwellings if geotopsis_categories==4 
qui matrix list e(b)
local den1=e(b)[1,1]
qui total n_ppl_agric if geotopsis_categories==4 
qui matrix list e(b)
local den2=e(b)[1,1]
local cea=`num'/`den1'
dis in red "The overall CEA #1 is `cea'" //CEA#1: denom is # of dwellings possibly preserved
local cea=`num'/`den2'
dis in red "The overall CEA #2 is `cea'" //CEA#1: denom is # of jobs in agriculture possibly preserved



